{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rosie-Chenyr/Advanced-H1B-LCA-Data-Analysis-Project/blob/main/class04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghu9a5jRdo_B"
      },
      "outputs": [],
      "source": [
        "# RNN with GPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjRCd7FEd1Kp",
        "outputId": "ee0caf38-3d2c-487a-8467-54cbf518d62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sentences\n",
        "sentences = [\n",
        "    \"i loved this movie\",\n",
        "    \"the acting was terrible\",\n",
        "    \"great performances by the cast\",\n",
        "    \"i fell asleep during the film\",\n",
        "    \"this film is a masterpiece\",\n",
        "    \"the special effects were amazing\",\n",
        "    \"worst movie i have seen\",\n",
        "    \"the soundtrack was beautiful\"\n",
        "]"
      ],
      "metadata": {
        "id": "X6DdFwuseCxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple vocabulary\n",
        "all_words = []\n",
        "for sentence in sentences:\n",
        "    all_words.extend(sentence.split())\n",
        "\n",
        "vocab = sorted(set(all_words))\n",
        "word2idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx2word = {i: word for i, word in enumerate(vocab)}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(f\"Vocabulary: {vocab}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf_DU5SheGbY",
        "outputId": "e7d1014c-83fb-44a2-82b2-a2379d081ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 28\n",
            "Vocabulary: ['a', 'acting', 'amazing', 'asleep', 'beautiful', 'by', 'cast', 'during', 'effects', 'fell', 'film', 'great', 'have', 'i', 'is', 'loved', 'masterpiece', 'movie', 'performances', 'seen', 'soundtrack', 'special', 'terrible', 'the', 'this', 'was', 'were', 'worst']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sentences to sequences\n",
        "def sentence_to_indices(sentence, word2idx):\n",
        "  return [word2idx[word] for word in sentence.split()]\n",
        "\n",
        "sequences = [sentence_to_indices(sentence, word2idx) for sentence in sentences]\n",
        "print(sequences)\n",
        "max_length = max(len(seq) for seq in sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJHgJJpk2AP0",
        "outputId": "0b985dab-d6f0-4acc-dada-82b9d8120492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13, 15, 24, 17], [23, 1, 25, 22], [11, 18, 5, 23, 6], [13, 9, 3, 7, 23, 10], [24, 10, 14, 0, 16], [23, 21, 8, 26, 2], [27, 17, 13, 12, 19], [23, 20, 25, 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "def pad_sequence(seq, max_length):\n",
        "  return seq + [0] * (max_length - len(seq)) # Using 0 as padding\n",
        "\n",
        "padded_sequences = [pad_sequence(seq, max_length) for seq in sequences]\n",
        "print(padded_sequences)\n",
        "X = torch.LongTensor(padded_sequences).to(device)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqeTrBwf2-rY",
        "outputId": "eaeeb52f-c375-412c-ae11-556896794b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13, 15, 24, 17, 0, 0], [23, 1, 25, 22, 0, 0], [11, 18, 5, 23, 6, 0], [13, 9, 3, 7, 23, 10], [24, 10, 14, 0, 16, 0], [23, 21, 8, 26, 2, 0], [27, 17, 13, 12, 19, 0], [23, 20, 25, 4, 0, 0]]\n",
            "tensor([[13, 15, 24, 17,  0,  0],\n",
            "        [23,  1, 25, 22,  0,  0],\n",
            "        [11, 18,  5, 23,  6,  0],\n",
            "        [13,  9,  3,  7, 23, 10],\n",
            "        [24, 10, 14,  0, 16,  0],\n",
            "        [23, 21,  8, 26,  2,  0],\n",
            "        [27, 17, 13, 12, 19,  0],\n",
            "        [23, 20, 25,  4,  0,  0]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to one-hot encoding\n",
        "def to_one_hot(X, vocab_size):\n",
        "    one_hot = torch.zeros(X.size(0), X.size(1), vocab_size, device=device)\n",
        "    for i in range(X.size(0)):\n",
        "        for j in range(X.size(1)):\n",
        "            one_hot[i, j, X[i, j]] = 1\n",
        "    return one_hot\n",
        "\n",
        "X_one_hot = to_one_hot(X, vocab_size)\n",
        "print(X_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9H4eOSYehwg",
        "outputId": "4f0382bb-61bf-4d4c-b7e3-0aabcae0d054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 1.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RNN autoencoder\n",
        "class RNNAutoencoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(RNNAutoencoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.RNN(vocab_size, hidden_size, batch_first=True)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        seq_len = x.size(1)\n",
        "\n",
        "        # Encoder\n",
        "        _, hidden = self.encoder(x)\n",
        "\n",
        "        # Create decoder inpyt (repeat hidden state for each time step)\n",
        "        decoder_input = hidden.permute(1, 0, 2).repeat(1, seq_len, 1)\n",
        "\n",
        "        # Decode\n",
        "        outputs, _ = self.decoder(decoder_input)\n",
        "\n",
        "        # Project to vocabulary space\n",
        "        outputs = self.output_layer(outputs)\n",
        "\n",
        "        return outputs, hidden.squeeze(0)"
      ],
      "metadata": {
        "id": "mNZTNwoVf7aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model and move to GPU\n",
        "hidden_size = 10 # Size of the hidden/encoded representation\n",
        "model = RNNAutoencoder(vocab_size, hidden_size).to(device)"
      ],
      "metadata": {
        "id": "GdOOy-0y5St6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "dfKp6RiQ5vGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    # Make sure model is in training mode\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs, encoded = model(X_one_hot)\n",
        "\n",
        "    # Reshape for cross entropy loss\n",
        "    outputs = outputs.view(-1, vocab_size)\n",
        "    targets = X.view(-1)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuZa3-Fmggcs",
        "outputId": "ad9a95a8-ce22-4d3c-ac37-465fe8514ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.0098\n",
            "Epoch [200/1000], Loss: 0.0080\n",
            "Epoch [300/1000], Loss: 0.0066\n",
            "Epoch [400/1000], Loss: 0.0056\n",
            "Epoch [500/1000], Loss: 0.0047\n",
            "Epoch [600/1000], Loss: 0.0041\n",
            "Epoch [700/1000], Loss: 0.0035\n",
            "Epoch [800/1000], Loss: 0.0031\n",
            "Epoch [900/1000], Loss: 0.0027\n",
            "Epoch [1000/1000], Loss: 0.0024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the autoencoder\n",
        "model.eval()  # Important: set to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs, encoded_data = model(X_one_hot)\n",
        "\n",
        "    # Find the most likely word at each position\n",
        "    _, predicted_indices = torch.max(outputs, dim=2)\n",
        "\n",
        "    # Move data back to CPU for processing\n",
        "    predicted_indices = predicted_indices.cpu()\n",
        "    encoded_data = encoded_data.cpu()\n",
        "\n",
        "    # Print original and reconstructed texts\n",
        "    print(\"\\nOriginal vs Reconstructed:\")\n",
        "    for i in range(len(sentences)):\n",
        "        original = sentences[i]\n",
        "\n",
        "        reconstructed_words = []\n",
        "        for j in range(len(predicted_indices[i])):\n",
        "            idx = predicted_indices[i][j].item()\n",
        "            if idx in idx2word:\n",
        "                reconstructed_words.append(idx2word[idx])\n",
        "\n",
        "        reconstructed = ' '.join(reconstructed_words)\n",
        "\n",
        "        print(f\"Original: {original}\")\n",
        "        print(f\"Reconstructed: {reconstructed}\")\n",
        "        print()\n",
        "\n",
        "    # Print encoded representations\n",
        "    print(\"\\nEncoded representations (10-dimensional):\")\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        print(f\"{sentence}: {encoded_data[i].numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42B2V35jgxm2",
        "outputId": "f7dbfa6f-c42f-4ff2-f293-f93937a453d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original vs Reconstructed:\n",
            "Original: i loved this movie\n",
            "Reconstructed: i loved this movie a a\n",
            "\n",
            "Original: the acting was terrible\n",
            "Reconstructed: the acting was terrible a a\n",
            "\n",
            "Original: great performances by the cast\n",
            "Reconstructed: great performances by the cast a\n",
            "\n",
            "Original: i fell asleep during the film\n",
            "Reconstructed: i fell asleep during the film\n",
            "\n",
            "Original: this film is a masterpiece\n",
            "Reconstructed: this film is a masterpiece a\n",
            "\n",
            "Original: the special effects were amazing\n",
            "Reconstructed: the special effects were amazing a\n",
            "\n",
            "Original: worst movie i have seen\n",
            "Reconstructed: worst movie i have seen a\n",
            "\n",
            "Original: the soundtrack was beautiful\n",
            "Reconstructed: the soundtrack was beautiful a a\n",
            "\n",
            "\n",
            "Encoded representations (10-dimensional):\n",
            "i loved this movie: [-0.47268057  0.97325027 -0.99186295 -0.76696897  0.8042304   0.96708065\n",
            "  0.89488065  0.11419757  0.96373004 -0.492016  ]\n",
            "the acting was terrible: [-0.95551366  0.86767507 -0.9756296  -0.9938029  -0.09841057  0.7844355\n",
            " -0.51801544  0.97147757  0.9421622   0.8325809 ]\n",
            "great performances by the cast: [-0.9917656  -0.9426284   0.9633353  -0.99986124 -0.8185162   0.8637111\n",
            " -0.9462953   0.7907139  -0.69098884  0.9929438 ]\n",
            "i fell asleep during the film: [ 0.6766507   0.9752443   0.4322684  -0.99196726  0.9845237   0.38794687\n",
            "  0.92458946 -0.9962304  -0.2799959  -0.4734284 ]\n",
            "this film is a masterpiece: [ 0.89303845  0.98745346 -0.9487053  -0.98587734 -0.9377466   0.11716793\n",
            "  0.44624516 -0.36593643  0.7610247  -0.6700102 ]\n",
            "the special effects were amazing: [-0.99395293  0.6323767   0.29767963 -0.99789315  0.8081105   0.6954428\n",
            " -0.5092787   0.7291328   0.72190124  0.97111845]\n",
            "worst movie i have seen: [ 0.94184273  0.9415088  -0.9927392   0.9768486   0.79929507  0.958946\n",
            "  0.9836834  -0.9016392   0.9683995  -0.9365657 ]\n",
            "the soundtrack was beautiful: [-0.8834011   0.840432    0.9070422  -0.998482    0.7859725   0.48682314\n",
            "  0.488402   -0.79337555  0.72988075  0.9463669 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gviP_jH_7Lnj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}